# general
seed: 100
exp_id: 100
log_dir: "logs"

dataset_pt: "web-text-tok-llama2.hf"
split_pt: #Â none
dataset: "muse-news-train.hf"
split: "forget"
use_chunking: False

gen_eval_name: "news" # "news" # "general" #
tokenizer: "muse-news-target"
network: "muse-news-target" 
network_base: # none

# early stopping check
stop_metric: "verbmem_f"
stop_val: 22.0 # stops once metric 'stop_metric' is smaller or equal to 'stop_val'

context: 1024

loss: "nlul"
penalty: "qkl"

optimizer: "sgd"
lr: 0.0005
b1: 0.9
b2: 0.95
momentum: 0.9
warmup: 0

micro_batch: 8
forget_accum_steps: 5
kl_accum_steps: 5
eval_accum_steps: 5
eval_every: 99

epochs: 4
steps: 100
clip: 1.0

alpha: 0.05
beta: 1.0
delta: 0.005
damp: 5.0

# referred to losses
tol: 0.02
beta_npo: 0.1
